Алгоритм CART с использованием индекса Джини в качестве критерия разделения

Процесс построения дерева:
1. Начинаем с корневого узла, содержащего все данные
2. Для каждого признака и каждого возможного значения разделения вычисляем критерий качества
3. Выбираем разделение с наилучшим значением критерия
4. Рекурсивно повторяем процесс для дочерних узлов
5. Останавливаемся при достижении критериев:
5.1 Максимальная глубина дерева
5.2 Минимальное количество образцов в узле
5.3 Невозможность улучшить разделение

Описание функций:
seed(s): Инициализирует генератор случайных чисел c заданным начальным значением
random(): Генерирует случайное число между 0 и 1
randrange(max): Возвращает случайное целое число от 0 до max-1

load_csv(filename): Загружает CSV-файл и преобразует его в двумерный массив
strColumnToFloat(dataset, column): Преобразует указанный столбец из строк в массив дробных чисел

crossValidationSplit(dataset, n_folds): Разделяет набор данных на n_folds частей для кросс-валидации
accuracyMetric(actual, predicted): Вычисляет точность предсказаний в процентах
evaluateAlgorithm(...): Оценивает алгоритм с помощью кросс-валидации, возвращая массив оценок точности для каждого фолда

testSplit(index, value, dataset) - разделяет dataset на две части по значению value в столбце index
giniIndex(groups, classes) - вычисляет индекс Джини для оценки качества разделения данных
getSplit(dataset) - находит лучшее разделение данных, перебирая все возможные разделения по всем признакам

toTerminal(group) - Создает лист, содержащий наиболее часто встречающийся класс в группе
split(node, maxDepth, minSize, depth) - рекурсивно разделяет узлы дерева

buildTree(train, maxDepth, minSize) - строит дерево решений, начиная с корневого узла
predict(node, row) - рекурсивно проходит по дереву, чтобы сделать предсказание для одной строки данных
decisionTree(train, test, max_depth, min_size) - строит дерево на обучающих данных и делает предсказания для тестовых данных
